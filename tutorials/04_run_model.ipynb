{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc071d2d",
   "metadata": {},
   "source": [
    "# Tutorial 04: Run the Training and Test Phases of the WGAST Model\n",
    "\n",
    "In this tutorial, we will run the **WGAST** model on the structured dataset we prepared earlier. This includes:\n",
    "\n",
    "- Setting up all necessary parameters and model configurations.\n",
    "- Launching the training process.\n",
    "- Evaluating the trained model.\n",
    "\n",
    "ðŸ“Œ This tutorial is fully customizable. The default parameters match the settings used in our paper, feel free to adjust them based on your data or hardware capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a656bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import time\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Add the project root to sys.path to allow imports from other folders (e.g., 'runner', 'data_loader', etc.)\n",
    "sys.path.append(os.path.abspath('..'))  # Assumes this notebook is in /tutorials/\n",
    "\n",
    "from runner.experiment import Experiment  # Main class to manage training and testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c387a4",
   "metadata": {},
   "source": [
    "## Step 01 : Define and Initialize Model Parameters (from the Paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481adb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialization\n",
      "There are 7884208 trainable parameters for generator.\n",
      "There are 2765505 trainable parameters for nlayerdiscriminator.\n"
     ]
    }
   ],
   "source": [
    "# === Configuration Class ===\n",
    "class Options:\n",
    "    \"\"\"\n",
    "    Stores all hyperparameters and paths used during training/testing.\n",
    "\n",
    "    âš ï¸ NOTE: The folder './data/Tdivision' must be generated by the previous tutorials:\n",
    "        - 01_data_download.ipynb\n",
    "        - 02_data_preparation.ipynb\n",
    "        - 03_data_structuring.ipynb\n",
    "\n",
    "    ðŸ“Œ These hyperparameters correspond to the settings used in the paper.\n",
    "       Feel free to adjust them for your own experiments.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Training settings\n",
    "        self.lr = 2e-4                  # Learning rate\n",
    "        self.batch_size = 32           # Batch size\n",
    "        self.epochs = 110              # Number of training epochs\n",
    "\n",
    "        # Hardware settings\n",
    "        self.cuda = True               # Enable CUDA if available\n",
    "        self.ngpu = 1                  # Number of GPUs to use\n",
    "        self.num_workers = 8           # Number of data loading workers\n",
    "\n",
    "        # Data paths\n",
    "        self.save_dir = Path('./data/Tdivision')      # Where to save outputs\n",
    "        self.data_dir = Path('./data/Tdivision')      # Base data directory\n",
    "        self.train_dir = Path('./data/Tdivision/train')  # Training data path\n",
    "        self.test_dir = Path('./data/Tdivision/test')    # Testing data path\n",
    "\n",
    "        # Image and patch parameters\n",
    "        self.image_size = [400, 400]   # Size of input images\n",
    "        self.patch_size = [32, 32]     # Size of image patches\n",
    "        self.patch_stride = 8          # Stride for patch extraction\n",
    "        self.test_patch = 32           # Patch size during testing\n",
    "\n",
    "        # Model options\n",
    "        self.ifAdaIN = True            # Use AdaIN for feature normalization\n",
    "        self.ifAttention = True        # Use attention mechanism\n",
    "        self.ifTwoInput = False        # Use two input streams (if applicable)\n",
    "        \n",
    "        # Loss weights (used in final objective function)\n",
    "        self.a = 1e-2\n",
    "        self.b = 1\n",
    "        self.c = 1\n",
    "        self.d = 1\n",
    "\n",
    "# === Set Options ===\n",
    "opt = Options()\n",
    "\n",
    "# === Set random seed for reproducibility ===\n",
    "torch.manual_seed(2024)\n",
    "opt.cuda = True  # Enable CUDA if available\n",
    "if not torch.cuda.is_available():\n",
    "    opt.cuda = False\n",
    "\n",
    "if opt.cuda:\n",
    "    torch.cuda.manual_seed_all(2024)\n",
    "    cudnn.benchmark = True       # Enable benchmark mode for optimal performance\n",
    "    cudnn.deterministic = True   # Make training deterministic (reproducible)\n",
    "\n",
    "# === Run Experiment ===\n",
    "# This initializes the training/testing workflow\n",
    "experiment = Experiment(opt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bea1cc3",
   "metadata": {},
   "source": [
    "## Step 02 : Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cd87e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.epochs > 0:\n",
    "    start_time = time.time()  # Start measuring training time\n",
    "    \n",
    "    # Begin training process using parameters defined earlier\n",
    "    # - opt.train_dir: Path to the training dataset (prepared in previous tutorials)\n",
    "    # - patch_size / patch_stride: How images are split into training patches\n",
    "    # - batch_size: Number of samples per training batch\n",
    "    # - num_workers: Number of subprocesses used for data loading\n",
    "    # - epochs: Number of full passes over the dataset\n",
    "    predictions = experiment.train(opt.train_dir,\n",
    "                                   opt.patch_size, \n",
    "                                   opt.patch_stride, \n",
    "                                   opt.batch_size,\n",
    "                                   num_workers=1, \n",
    "                                   epochs=opt.epochs)\n",
    "\n",
    "    end_time = time.time()  # Stop measuring training time\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Training took {elapsed_time:.2f} seconds\")  # Display training duration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472dc8c2",
   "metadata": {},
   "source": [
    "## Step 03 : Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7423e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the trained model using the test dataset\n",
    "# - opt.test_dir: Path to the test dataset (should be pre-generated in earlier steps)\n",
    "# - patch_size: Size of the patches used for testing\n",
    "# - num_workers: Number of parallel data loading workers\n",
    "\n",
    "results = experiment.test(opt.test_dir,\n",
    "                          opt.patch_size,\n",
    "                          num_workers=1)\n",
    "\n",
    "# Print or log the results as needed\n",
    "print(\"Testing completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PHD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
